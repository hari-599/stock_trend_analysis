{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA COLLECTION**"
      ],
      "metadata": {
        "id": "yd0MuNe-xqSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import datetime\n",
        "!pip install pandas_datareader\n",
        "!pip install yfinance\n"
      ],
      "metadata": {
        "id": "LyY87JVVoaJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the collection stage, it used to collect newses based on the ticker keyword. It used 'Alphavantage' for the collection of news."
      ],
      "metadata": {
        "id": "Chto35y6x4T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=AAPL&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/apple.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'AAPL'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "8gTS-LwRiE8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=MSFT&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/msft.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'MSFT'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "yd32OATvCO_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=TSLA&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/tsla.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'TSLA'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "d5HR-MbTuR6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=GOOGL&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/googl.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'GOOGL'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "CmK2WF4-ySYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=GOOG&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/goog.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'GOOG'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "Rzm7Y5xcyv7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=NVDA&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/nvda.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'NVDA'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "X74aON1KzlYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=AMD&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/amd.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'AMD'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "AXXbnfi4zvGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=PFE&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/pfe.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'PFE'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "lUpy1Otl0fAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"9A8S2NN68B7CMXLW\"\n",
        "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=JNJ&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'\n",
        "csv_name = '/content/drive/My Drive/Data_msc/jnj.csv'\n",
        "# Define the start and end dates of the desired period\n",
        "start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')\n",
        "current_date = start_date\n",
        "\n",
        "with open(csv_name, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Title\", \"Description\", \"Date\", 'ticker', 'topic'])\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        # Format current date as per the API requirement\n",
        "        formatted_date = current_date.strftime('%Y%m%d')\n",
        "\n",
        "        # Construct the API URL with the current interval\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_date = current_date + datetime.timedelta(days=60)\n",
        "        formatted_end_date = end_date.strftime('%Y%m%d')\n",
        "        start_time = f\"{formatted_date}T0130\"\n",
        "        end_time = f\"{formatted_end_date}T0130\"\n",
        "        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)\n",
        "\n",
        "        # Make the API call\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'feed' in data:\n",
        "          articles=data['feed']\n",
        "          for article in articles:\n",
        "              title = article[\"title\"]\n",
        "              description = article[\"summary\"]\n",
        "              date = article[\"time_published\"].split(\"T\")[0]\n",
        "              ticker = 'JNJ'\n",
        "              topics = data[\"feed\"][0][\"topics\"]\n",
        "              topic_with_highest_score = max(topics, key=lambda x: float(x[\"relevance_score\"]))\n",
        "              topic = topic_with_highest_score[\"topic\"]\n",
        "              writer.writerow([title, description, date, ticker, topic])\n",
        "\n",
        "          # Increment current date by one month\n",
        "          current_date = current_date + datetime.timedelta(days=60)\n",
        "\n",
        "        else:\n",
        "          print(f\"No news articles found for date {formatted_date}\")\n",
        "        if current_date > end_date:\n",
        "          break\n",
        "\n",
        "print(\"Data written to CSV successfully.\")\n"
      ],
      "metadata": {
        "id": "vod27v0uBJNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}