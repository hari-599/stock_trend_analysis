{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV3Uk_InCewS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import yfinance as yf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Collected news data from drive\n"
      ],
      "metadata": {
        "id": "sk345dsKSAmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory containing the CSV files\n",
        "directory = '/content/drive/MyDrive/Data_msc/news/'\n",
        "# Get a list of all CSV files in the directory\n",
        "csv_files = glob.glob(directory + '*.csv')\n",
        "# Initialize an empty list to store the dataframes\n",
        "dfs = []\n",
        "# Read each CSV file and append its contents to the list of dataframes\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    dfs.append(df)\n",
        "# Concatenate all the dataframes into a single dataframe\n",
        "merged_df = pd.concat(dfs)\n",
        "# Path and filename for the merged CSV file\n",
        "merged_file = '/content/drive/MyDrive/Data_msc/merged_file.csv'\n",
        "# Save the merged dataframe as a CSV file\n",
        "merged_df.to_csv(merged_file, index=False)\n",
        "print(\"CSV files merged successfully!\")\n"
      ],
      "metadata": {
        "id": "OkWBiteP517l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Data_msc/merged_file.csv')"
      ],
      "metadata": {
        "id": "1rgRSjSo9wat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['ticker'].value_counts()"
      ],
      "metadata": {
        "id": "UFckjQwZ4SJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing unneccessary data by filtering topics"
      ],
      "metadata": {
        "id": "o3XfLRt0SJHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ['Economy - Fiscal', 'Economy - Monetary', 'IPO',\n",
        "          'Real Estate & Construction', 'Mergers & Acquisitions',\n",
        "          'Energy & Transportation', 'Finance','Financial Markets']\n",
        "data = data[data['topic'].isin(topics)]\n"
      ],
      "metadata": {
        "id": "FWWMXFWXTZPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
        "data['Date'] = data['Date'].dt.strftime('%Y-%m-%d')\n"
      ],
      "metadata": {
        "id": "gt3TO6jd3QA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Description'] = data['Title'] + ' ' + data['Description']\n",
        "data=data.drop('Title',axis=1)\n"
      ],
      "metadata": {
        "id": "h-LKE7e9_Mwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_n = data.groupby(['Date', 'ticker']).agg({\n",
        "    'Description': lambda x: ' '.join(x),  # Concatenate the text from the 'body' column\n",
        "}).reset_index()\n",
        "data_n=data_n.set_index(['Date','ticker'])\n"
      ],
      "metadata": {
        "id": "wDyQtiYUmVyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading historical stock prices with yfinance\n",
        "# Configuring tickers and period\n",
        "ticker_symbols = [\"AAPL\", \"GOOG\", \"AMZN\", \"TSLA\", \"MSFT\",\"JNJ\",\"AMD\",\"IVZ\",\"PFE\"]\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2023-06-01\"\n",
        "interval = \"1d\"\n",
        "\n",
        "# Adjusting all prices to stock splits and dividend payments\n",
        "auto_adjust = True\n",
        "\n",
        "# Using yfinance package to get data from Yahoo Finance for each ticker\n",
        "tickers = yf.Tickers(ticker_symbols)\n",
        "tickers_df = tickers.history(start=start_date, end=end_date, interval=interval, auto_adjust=auto_adjust)\n",
        "\n",
        "# Investigating data\n",
        "print(tickers_df.shape)\n",
        "tickers_df.head(20)"
      ],
      "metadata": {
        "id": "rMueAcVZ46qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df = tickers_df.stack(level=1).rename_axis(['Date', 'Ticker'])\n",
        "transformed_df.head(10)"
      ],
      "metadata": {
        "id": "lxWd4qJn-EGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing columns to keep\n",
        "cols = ['Close', 'Open', 'Volume']\n",
        "\n",
        "# Creating a new dataFrame with selected columns\n",
        "stock_df = transformed_df[cols].copy()\n",
        "\n",
        "\n",
        "def calculate_log_change(x):\n",
        "    result = np.log(x) - np.log(x.shift(1))\n",
        "    return result\n",
        "\n",
        "def create_binary_variable(x):\n",
        "    result = np.where(x >= 0, 1, 0)\n",
        "    return result\n",
        "\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "def create_multiclass(x):\n",
        "    result = 2 if x >= 0.005 else (0 if x <= -0.005 else 1)\n",
        "    return result\n",
        "\n",
        "# Creating columns for log returns and log volume change and ensuring that its calculated on individual ticker level\n",
        "stock_df['log_ret'] = stock_df.groupby(level='Ticker')['Close'].apply(calculate_log_change)\n",
        "stock_df['log_volume_change'] = stock_df.groupby(level='Ticker')['Volume'].apply(calculate_log_change)\n",
        "\n",
        "# Creating columns for binary variables\n",
        "# Value of 1 if equal or above 0, 0 if below\n",
        "stock_df['log_ret_binary'] = stock_df['log_ret'].apply(create_binary_variable)\n",
        "stock_df['log_volume_change_binary'] = stock_df['log_volume_change'].apply(create_binary_variable)\n",
        "\n",
        "# Creating the multiclass target variable\n",
        "# Creating function for defining the Up (2), Stable (1), and Down (0) classes\n",
        "stock_df['target'] = stock_df['log_ret'].apply(create_multiclass)\n",
        "\n",
        "stock_df.head(20)"
      ],
      "metadata": {
        "id": "KKq4RY5c-Ji6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "v11lmTdB-V_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.reset_index(inplace=True)\n",
        "stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
        "stock_df.set_index(['Date', 'Ticker'], inplace=True)\n",
        "stock_df"
      ],
      "metadata": {
        "id": "m5SENrlq-dcZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}